{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Replicating LeNet in tensorflow using Keras\n"
      ],
      "metadata": {
        "id": "nkI1Sry2jUFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dropout, Dense, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adadelta"
      ],
      "metadata": {
        "id": "gB7DB5NtjlKR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() # loading the MNIST dataset\n",
        "\n",
        "img_rows = x_train[0].shape[0]  # storing the rows\n",
        "img_cols = x_train[1].shape[0]  # storing the columns\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) #changing the shape of training data to (60000, 28, 28) to (60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) #changing the shape of test data to (60000, 28, 28) to (60000, 28, 28, 1)\n",
        "\n",
        "input_shape = (img_rows, img_cols, 1) # storing the shape of a single image\n",
        "\n",
        "x_train = x_train.astype('float32') # converting the train images into 'float32' datatype\n",
        "x_test = x_test.astype('float32')  # converting the test images into 'float32' datatype\n",
        "\n",
        "x_train /= 255  # Normalize the data by changing (0-255) to (0-1)\n",
        "x_test /= 255\n",
        "\n",
        "y_train = to_categorical(y_train)   # Now we one hot encode the outputs\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1]*x_train.shape[2]"
      ],
      "metadata": {
        "id": "IPm9pWqHlL-H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Replicate the layer"
      ],
      "metadata": {
        "id": "3wR5tjL-wm_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(6, (5, 5), padding=\"same\", input_shape= input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
        "\n",
        "model.add(Conv2D(16, (5, 5), padding=\"same\", input_shape= input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
        "\n",
        "model.add(Conv2D(120, (5, 5), padding=\"same\", input_shape= input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dense(84))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\")) # softmax  (for classification)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adadelta(), metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIPyULKDwsmr",
        "outputId": "b3981506-3344-44a2-ed20-72a1f0ee3ed9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 16)        2416      \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 14, 14, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 7, 7, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 7, 7, 120)         48120     \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 7, 7, 120)         0         \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 3, 3, 120)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1080)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 120)               129720    \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 120)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 191,426\n",
            "Trainable params: 191,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    validation_data =(x_test, y_test),\n",
        "                    shuffle = True)\n",
        "model.save(\"mnist_LeNet.h5\")\n",
        "scores = model.evaluate(x_test, y_test, verbose = 1)\n",
        "print('Test Loss : ', scores[0])\n",
        "print('Test accuracy : ', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfQXHeORxax7",
        "outputId": "1c9db04d-28f2-41c6-eea2-1775a864ba78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 69s 288ms/step - loss: 2.3003 - accuracy: 0.0862 - val_loss: 2.2983 - val_accuracy: 0.0851\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 64s 274ms/step - loss: 2.2962 - accuracy: 0.0961 - val_loss: 2.2938 - val_accuracy: 0.0971\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 64s 274ms/step - loss: 2.2915 - accuracy: 0.1078 - val_loss: 2.2887 - val_accuracy: 0.1095\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 68s 290ms/step - loss: 2.2865 - accuracy: 0.1157 - val_loss: 2.2834 - val_accuracy: 0.1183\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 66s 283ms/step - loss: 2.2812 - accuracy: 0.1194 - val_loss: 2.2776 - val_accuracy: 0.1221\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 67s 287ms/step - loss: 2.2752 - accuracy: 0.1212 - val_loss: 2.2711 - val_accuracy: 0.1257\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 66s 280ms/step - loss: 2.2684 - accuracy: 0.1280 - val_loss: 2.2634 - val_accuracy: 0.1353\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 67s 285ms/step - loss: 2.2603 - accuracy: 0.1396 - val_loss: 2.2544 - val_accuracy: 0.1489\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 68s 292ms/step - loss: 2.2507 - accuracy: 0.1552 - val_loss: 2.2436 - val_accuracy: 0.1648\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 66s 283ms/step - loss: 2.2392 - accuracy: 0.1714 - val_loss: 2.2305 - val_accuracy: 0.1815\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 65s 275ms/step - loss: 2.2252 - accuracy: 0.1879 - val_loss: 2.2146 - val_accuracy: 0.2009\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 67s 287ms/step - loss: 2.2082 - accuracy: 0.2021 - val_loss: 2.1952 - val_accuracy: 0.2187\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 66s 282ms/step - loss: 2.1871 - accuracy: 0.2226 - val_loss: 2.1710 - val_accuracy: 0.2358\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 66s 279ms/step - loss: 2.1609 - accuracy: 0.2467 - val_loss: 2.1408 - val_accuracy: 0.2708\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 66s 279ms/step - loss: 2.1281 - accuracy: 0.2862 - val_loss: 2.1032 - val_accuracy: 0.3273\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 67s 286ms/step - loss: 2.0870 - accuracy: 0.3506 - val_loss: 2.0561 - val_accuracy: 0.4066\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 65s 275ms/step - loss: 2.0354 - accuracy: 0.4369 - val_loss: 1.9969 - val_accuracy: 0.5042\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 67s 283ms/step - loss: 1.9706 - accuracy: 0.5315 - val_loss: 1.9231 - val_accuracy: 0.5846\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 65s 276ms/step - loss: 1.8906 - accuracy: 0.6053 - val_loss: 1.8327 - val_accuracy: 0.6415\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 67s 283ms/step - loss: 1.7936 - accuracy: 0.6555 - val_loss: 1.7249 - val_accuracy: 0.6818\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 64s 274ms/step - loss: 1.6794 - accuracy: 0.6883 - val_loss: 1.6000 - val_accuracy: 0.7068\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 65s 275ms/step - loss: 1.5508 - accuracy: 0.7143 - val_loss: 1.4640 - val_accuracy: 0.7230\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 66s 281ms/step - loss: 1.4153 - accuracy: 0.7333 - val_loss: 1.3260 - val_accuracy: 0.7416\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 65s 275ms/step - loss: 1.2820 - accuracy: 0.7497 - val_loss: 1.1954 - val_accuracy: 0.7573\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 65s 278ms/step - loss: 1.1600 - accuracy: 0.7653 - val_loss: 1.0801 - val_accuracy: 0.7742\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 68s 288ms/step - loss: 1.0541 - accuracy: 0.7783 - val_loss: 0.9821 - val_accuracy: 0.7854\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 65s 277ms/step - loss: 0.9653 - accuracy: 0.7882 - val_loss: 0.9018 - val_accuracy: 0.7983\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 64s 273ms/step - loss: 0.8922 - accuracy: 0.7979 - val_loss: 0.8355 - val_accuracy: 0.8046\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 66s 283ms/step - loss: 0.8321 - accuracy: 0.8043 - val_loss: 0.7810 - val_accuracy: 0.8165\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 64s 273ms/step - loss: 0.7826 - accuracy: 0.8114 - val_loss: 0.7359 - val_accuracy: 0.8239\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 65s 278ms/step - loss: 0.7411 - accuracy: 0.8184 - val_loss: 0.6985 - val_accuracy: 0.8275\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 65s 275ms/step - loss: 0.7059 - accuracy: 0.8241 - val_loss: 0.6663 - val_accuracy: 0.8348\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 64s 273ms/step - loss: 0.6755 - accuracy: 0.8292 - val_loss: 0.6380 - val_accuracy: 0.8413\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 67s 285ms/step - loss: 0.6490 - accuracy: 0.8342 - val_loss: 0.6138 - val_accuracy: 0.8456\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 64s 273ms/step - loss: 0.6258 - accuracy: 0.8387 - val_loss: 0.5918 - val_accuracy: 0.8512\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 65s 279ms/step - loss: 0.6050 - accuracy: 0.8435 - val_loss: 0.5725 - val_accuracy: 0.8556\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 65s 275ms/step - loss: 0.5862 - accuracy: 0.8477 - val_loss: 0.5547 - val_accuracy: 0.8596\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 66s 283ms/step - loss: 0.5691 - accuracy: 0.8520 - val_loss: 0.5387 - val_accuracy: 0.8627\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 68s 291ms/step - loss: 0.5534 - accuracy: 0.8554 - val_loss: 0.5239 - val_accuracy: 0.8666\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 64s 273ms/step - loss: 0.5386 - accuracy: 0.8589 - val_loss: 0.5099 - val_accuracy: 0.8699\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 67s 284ms/step - loss: 0.5248 - accuracy: 0.8625 - val_loss: 0.4973 - val_accuracy: 0.8716\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 67s 287ms/step - loss: 0.5125 - accuracy: 0.8651 - val_loss: 0.4856 - val_accuracy: 0.8743\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 64s 274ms/step - loss: 0.5010 - accuracy: 0.8676 - val_loss: 0.4745 - val_accuracy: 0.8767\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 64s 274ms/step - loss: 0.4902 - accuracy: 0.8698 - val_loss: 0.4645 - val_accuracy: 0.8796\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 66s 279ms/step - loss: 0.4801 - accuracy: 0.8718 - val_loss: 0.4548 - val_accuracy: 0.8824\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 64s 274ms/step - loss: 0.4705 - accuracy: 0.8741 - val_loss: 0.4460 - val_accuracy: 0.8832\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 68s 290ms/step - loss: 0.4616 - accuracy: 0.8760 - val_loss: 0.4372 - val_accuracy: 0.8870\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 64s 272ms/step - loss: 0.4532 - accuracy: 0.8780 - val_loss: 0.4293 - val_accuracy: 0.8888\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 65s 277ms/step - loss: 0.4452 - accuracy: 0.8800 - val_loss: 0.4216 - val_accuracy: 0.8904\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 66s 283ms/step - loss: 0.4376 - accuracy: 0.8817 - val_loss: 0.4144 - val_accuracy: 0.8928\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4144 - accuracy: 0.8928\n",
            "Test Loss :  0.4143787622451782\n",
            "Test accuracy :  0.892799973487854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hi78vwN0QBz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}